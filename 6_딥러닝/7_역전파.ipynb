{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파란?(Backpropagation)\n",
    "- 인공신경망에서 가중치 업데이트를 위해 사용하는 알고리즘\n",
    "- 학습 과정에서 발새앟는 오차를 각 노드의 가중치를 업데이트하는 방법\n",
    "- 경사하강법과 같이 사용되면서, 출력값(예측값)과 실제 값의 차이를 최소화하는데 중점을 두고 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연쇄법칙(Chain Rule)\n",
    "- 연쇄 법칙은 함수 $y = f(g(x)) $의 미분을 구할 때 사용\n",
    "- $y $가 $( u = g(x) $)라는 중간 변수를 거쳐 계산된다고 생각하면, 연쇄 법칙에 의해 다음과 같이 표현\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{du} \\cdot \\frac{du}{dx}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 층을 거쳐서 하나의 입력값이 출력값으로 변환댈 때, \n",
    "- 각층의 출력은 다시 다음 층의 입력이 됩니다. \n",
    "- input, layer1, layer2, output 이 있을 때, \n",
    "    - 첫번째 미분은 layer2에 대하여 output 을 미분을 실행\n",
    "    - 두번째 미분은 layer1에 대하여 layer2 를 미분 실행\n",
    "1. **첫 번째 층**:\n",
    "   $$\n",
    "   Z_1 = W_1 \\cdot X + b_1\n",
    "   $$\n",
    "   $$\n",
    "   A_1 = f(Z_1)\n",
    "   $$\n",
    "2. **두 번째 층**:\n",
    "   $$\n",
    "   Z_2 = W_2 \\cdot A_1 + b_2\n",
    "   $$\n",
    "   $$\n",
    "   A_2 = f(Z_2)\n",
    "   $$\n",
    "3. **출력층**:\n",
    "   $$\n",
    "   Z_3 = W_3 \\cdot A_2 + b_3\n",
    "   $$\n",
    "   $$\n",
    "   \\hat{Y} = A_3 = f(Z_3)\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분 실행해보기 - 역전파를 통해서 실행\n",
    "1. **출력층에서의 기울기**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial Z_3} = \\frac{\\partial L}{\\partial \\hat{Y}} \\cdot \\frac{\\partial \\hat{Y}}{\\partial Z_3}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W_3} = \\frac{\\partial L}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial W_3}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial b_3} = \\frac{\\partial L}{\\partial Z_3}\n",
    "   $$\n",
    "\n",
    "2. **두 번째 은닉층에서의 기울기**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial W_2}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial b_2} = \\frac{\\partial L}{\\partial Z_2}\n",
    "   $$\n",
    "3. **첫 번째 은닉층에서의 기울기**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial A_1} \\cdot \\frac{\\partial A_1}{\\partial Z_1}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial Z_1} \\cdot \\frac{\\partial Z_1}{\\partial W_1}\n",
    "   $$\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial b_1} = \\frac{\\partial L}{\\partial Z_1}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드로 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "def relu_dev(x):\n",
    "    return np.where(x >0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 가중치와 편향을 랜덤을 설정\n",
    "def init_weights(input_size, hidden_size, output_size):\n",
    "    np.random.seed(11)\n",
    "\n",
    "    W_1 = np.random.randn(input_size, hidden_size)\n",
    "    b_1 = np.zeros((1, hidden_size))\n",
    "\n",
    "    W_2 = np.random.randn(hidden_size, output_size)\n",
    "    b_2 = np.zeros((1, output_size))\n",
    "    return W_1, b_1, W_2, b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파 함수\n",
    "def forward_propagation(X, W_1, b_1, W_2, b_2):\n",
    "    # 첫번째 Layer\n",
    "    Z_1 = np.dot(X, W_1) + b_1\n",
    "    A_1 = relu(Z_1)\n",
    "\n",
    "    # 두번째 Layer\n",
    "    Z_2 = np.dot(A_1, W_2) + b_2\n",
    "    A_2 = relu(Z_2)\n",
    "\n",
    "    return Z_1, A_1, Z_2, A_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파 함수\n",
    "def forward_propagation(X, W_1, b_1, W_2, b_2):\n",
    "    # 첫번째 Layer\n",
    "    Z_1 = np.dot(X, W_1) + b_1\n",
    "    A_1 = relu(Z_1)\n",
    "\n",
    "    # 두번째 Layer\n",
    "    Z_2 = np.dot(A_1, W_2) + b_2\n",
    "    A_2 = relu(Z_2)\n",
    "\n",
    "    return Z_1, A_1, Z_2, A_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 업데이트 함수\n",
    "def update_weights(W_1, b_1, W_2, b_2, dW_1, db_1, dW_2, db_2, learning_rate):\n",
    "    W_1 -= learning_rate * dW_1\n",
    "    b_1 -= learning_rate * db_1\n",
    "\n",
    "    W_2 -= learning_rate * dW_2\n",
    "    b_2 -= learning_rate * db_2\n",
    "\n",
    "    return W_1, b_1, W_2, b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용함수(MSE)\n",
    "def compute_cost(A_2, Y):\n",
    "    m = Y.shape[0]\n",
    "    cost = (1/m) * np.sum((A_2 - Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3) (100, 1)\n"
     ]
    }
   ],
   "source": [
    "# 학습할 데이터\n",
    "X = np.random.rand(100,3)\n",
    "Y = np.random.rand(100,1)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# 모델 초기화\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 5\n",
    "ouput_size = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1, b_1, W_2, b_2 = init_weights(input_size, hidden_size, ouput_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 하이퍼 파라미터 설정\n",
    "learning_rate = 0.01\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 0.29617825471294423\n",
      "Iteration 100, Cost: 0.15269541445708593\n",
      "Iteration 200, Cost: 0.1361997979546046\n",
      "Iteration 300, Cost: 0.12646802945091326\n",
      "Iteration 400, Cost: 0.11914873921362253\n",
      "Iteration 500, Cost: 0.11360293902089343\n",
      "Iteration 600, Cost: 0.1093644928277771\n",
      "Iteration 700, Cost: 0.10602391756213714\n",
      "Iteration 800, Cost: 0.10337393702103816\n",
      "Iteration 900, Cost: 0.10130153664427889\n",
      "Final Cost: 0.0996029506728323\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ReLU 함수와 그 미분 함수 정의\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# 초기 가중치와 편향 설정\n",
    "def initialize_weights(input_size, hidden_size, output_size):\n",
    "    np.random.seed(42)  # 재현성을 위해 시드 설정\n",
    "    W1 = np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 순전파 함수\n",
    "def forward_propagation(X, W1, b1, W2, b2):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = relu(Z2)  # 여기서는 회귀 문제를 위해 활성화 함수 사용 안함\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# 역전파 함수\n",
    "def backward_propagation(X, Y, Z1, A1, Z2, A2, W1, W2):\n",
    "    m = X.shape[0]\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1/m) * np.dot(A1.T, dZ2)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_derivative(Z1)\n",
    "    dW1 = (1/m) * np.dot(X.T, dZ1)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "    \n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# 가중치 업데이트 함수\n",
    "def update_weights(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 비용 함수 (MSE)\n",
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[0]\n",
    "    cost = (1/m) * np.sum((A2 - Y)**2)\n",
    "    return cost\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 3)  # 입력 데이터\n",
    "Y = np.random.rand(100, 1)  # 출력 데이터\n",
    "\n",
    "# 모델 초기화\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 5\n",
    "output_size = Y.shape[1]\n",
    "W1, b1, W2, b2 = initialize_weights(input_size, hidden_size, output_size)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# 경사하강법을 이용한 학습\n",
    "for i in range(iterations):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
    "    dW1, db1, dW2, db2 = backward_propagation(X, Y, Z1, A1, Z2, A2, W1, W2)\n",
    "    W1, b1, W2, b2 = update_weights(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        cost = compute_cost(A2, Y)\n",
    "        print(f\"Iteration {i}, Cost: {cost}\")\n",
    "\n",
    "# 최종 비용 출력\n",
    "final_cost = compute_cost(A2, Y)\n",
    "print(f\"Final Cost: {final_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 학습시 비용 값은 : 0.28050715536743137\n",
      "100번째 학습시 비용 값은 : 0.22305593899821646\n",
      "200번째 학습시 비용 값은 : 0.18148978926232306\n",
      "300번째 학습시 비용 값은 : 0.15719628052307497\n",
      "400번째 학습시 비용 값은 : 0.1299445795692305\n",
      "500번째 학습시 비용 값은 : 0.10449521360738043\n",
      "600번째 학습시 비용 값은 : 0.09277975562253016\n",
      "700번째 학습시 비용 값은 : 0.08762657800189057\n",
      "800번째 학습시 비용 값은 : 0.08627957366599676\n",
      "900번째 학습시 비용 값은 : 0.08612824468561733\n"
     ]
    }
   ],
   "source": [
    "# 학습해보기\n",
    "for i in range(epochs):\n",
    "    Z_1, A_1, Z_2, A_2 = forward_propagation(X, W_1, b_1, W_2, b_2)\n",
    "    dW_1, db_1, dW_2, db_2 = backward_propagation(X, Y, Z_1, A_1, Z_2, A_2, W_1, W_2)\n",
    "    W_1, b_1, W_2, b_2 = update_weights(W_1, b_1, W_2, b_2, dW_1, db_1, dW_2, db_2, learning_rate)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        cost = compute_cost(A_2, Y)\n",
    "        print(f\"{i}번째 학습시 비용 값은 :\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.38553946, -0.12752398,  0.63039514,  1.34103988, -0.28337825],\n",
       "        [-0.28597683,  1.34967434,  0.8747145 , -0.57277477,  0.41792644],\n",
       "        [-0.48307578, -0.42430458,  0.10641514, -1.94377297, -1.73688937]]),\n",
       " array([[-0.14504482, -0.27615878,  0.11353132, -0.2374223 , -0.16592391]]),\n",
       " array([[-0.53349839],\n",
       "        [-0.62402997],\n",
       "        [ 0.46785601],\n",
       "        [-0.76468007],\n",
       "        [-1.40329412]]),\n",
       " array([[0.26322109]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1, b1, W2, b2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
