{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. system prompt, human prompt 작성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], template='당신은 {language} 선생님입니다. {language} 로 간단하게 답변해주세요'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system 메시지 구성\n",
    "system_message = \"당신은 {language} 선생님입니다. {language} 로 간단하게 답변해주세요\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_message)\n",
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text} 에 대해서 얘기해줘'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human 메시지 구성\n",
    "human_message = \"{text} 에 대해서 얘기해줘\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_message)\n",
    "human_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 구성\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, \n",
    "     human_prompt]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "from langchain.chat_models import ChatOllama\n",
    "model = ChatOllama(model=\"llama3.1:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃풋 파서 설정\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "outputparser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 설정\n",
    "chain = chat_prompt | model | outputparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울입니다."
     ]
    }
   ],
   "source": [
    "result = chain.stream({\"language\" : \"english\", \"text\" : \"대한민국의 수도는어디인가요?\"})\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 퓨샷 프롬프트 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"question\": \"안녕하세요를 경상도 사투리로 어떻게 말하나요?\",\n",
    "     \"answer\": \"안녕하이소\"},\n",
    "    {\"question\": \"맛있게 먹어를 경상도 사투리로 어떻게 말하나요?\",\n",
    "     \"answer\" : \"마이 무라\"},\n",
    "    {\"question\": \"지금 뭐하고 있어?를 경상도 사투리로 어떻게 말하나요?\",\n",
    "     \"answer\" : \"지금 뭐하노?\"},    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'question'], template='\\n질문내용 :\\n{question}를 경상도 사투리로 어떻게 말하나요?\\n\\n사투리 :\\n{answer}')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "질문내용 :\n",
    "{question}를 경상도 사투리로 어떻게 말하나요?\n",
    "\n",
    "사투리 :\n",
    "{answer}\"\"\"\n",
    ")\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"\"\"질문내용 :\n",
    "    {question}\n",
    "    사투리 : \"\"\",\n",
    "    input_variables=['question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문내용 :\n",
      "안녕하세요를 경상도 사투리로 어떻게 말하나요?를 경상도 사투리로 어떻게 말하나요?\n",
      "\n",
      "사투리 :\n",
      "안녕하이소\n",
      "\n",
      "\n",
      "질문내용 :\n",
      "맛있게 먹어를 경상도 사투리로 어떻게 말하나요?를 경상도 사투리로 어떻게 말하나요?\n",
      "\n",
      "사투리 :\n",
      "마이 무라\n",
      "\n",
      "\n",
      "질문내용 :\n",
      "지금 뭐하고 있어?를 경상도 사투리로 어떻게 말하나요?를 경상도 사투리로 어떻게 말하나요?\n",
      "\n",
      "사투리 :\n",
      "지금 뭐하노?\n",
      "\n",
      "질문내용 :\n",
      "    안녕하세요 지금 뭐하고 있어요?\n",
      "    사투리 : \n"
     ]
    }
   ],
   "source": [
    "question = \"안녕하세요 지금 뭐하고 있어요?\"\n",
    "question_prompt = prompt.format(question=question)\n",
    "print(question_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경상도 사투리와 원어민 한국인의 대화는 다음과 같습니다.\n",
      "\n",
      "Q: 안녕하세요, 지금 뭐하고 있어요?\n",
      "A: 하이소, 무라하노?\n",
      "\n",
      " Q: 안녕하세요, 맛있게 먹었어요.\n",
      " A: 마무르, 미안하이요!\n",
      "\n",
      " Q: 안녕하세요, 지인이 왔어요.\n",
      " A: 하이소, 잘했어?"
     ]
    }
   ],
   "source": [
    "# chain 설정\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "result = chain.stream(\n",
    "    {\"question\", \"안녕하세요 지금 뭐하고 있어요?\"}\n",
    ")\n",
    "\n",
    "for chunk in result:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다양한 출력파서를 사용해보기\n",
    "- pydandtic\n",
    "- jsonoutputparser\n",
    "- comma\n",
    "- pandasDataframe\n",
    "- Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# 1. pydantic 방식으로 응답 결과 받도록 해보기\n",
    "# pydantic 클래스 정의\n",
    "class UserRequest(BaseModel):\n",
    "    date : str = Field(description=\"요청 시간\")\n",
    "    ask_type : str = Field(description=\"문의 종류\")\n",
    "    request_type : str = Field(description=\"요청 종류\")\n",
    "    expected_type : str = Field(description=\"기대되는 대응\")\n",
    "    text: str\n",
    "\n",
    "# pydantic parser 설정\n",
    "parser = PydanticOutputParser(pydantic_object=UserRequest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"date\": {\"title\": \"Date\", \"description\": \"\\\\uc694\\\\uccad \\\\uc2dc\\\\uac04\", \"type\": \"string\"}, \"ask_type\": {\"title\": \"Ask Type\", \"description\": \"\\\\ubb38\\\\uc758 \\\\uc885\\\\ub958\", \"type\": \"string\"}, \"request_type\": {\"title\": \"Request Type\", \"description\": \"\\\\uc694\\\\uccad \\\\uc885\\\\ub958\", \"type\": \"string\"}, \"expected_type\": {\"title\": \"Expected Type\", \"description\": \"\\\\uae30\\\\ub300\\\\ub418\\\\ub294 \\\\ub300\\\\uc751\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"type\": \"string\"}}, \"required\": [\"date\", \"ask_type\", \"request_type\", \"expected_type\", \"text\"]}\\n```'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 구성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 물건을 판매하는 판매자야. 아래의 질문에 적절한 대응을 하도록 해.\n",
    "    question:\n",
    "    {text}\n",
    "\n",
    "    FORMAT:\n",
    "    {format}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], partial_variables={'format': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"date\": {\"title\": \"Date\", \"description\": \"\\\\uc694\\\\uccad \\\\uc2dc\\\\uac04\", \"type\": \"string\"}, \"ask_type\": {\"title\": \"Ask Type\", \"description\": \"\\\\ubb38\\\\uc758 \\\\uc885\\\\ub958\", \"type\": \"string\"}, \"request_type\": {\"title\": \"Request Type\", \"description\": \"\\\\uc694\\\\uccad \\\\uc885\\\\ub958\", \"type\": \"string\"}, \"expected_type\": {\"title\": \"Expected Type\", \"description\": \"\\\\uae30\\\\ub300\\\\ub418\\\\ub294 \\\\ub300\\\\uc751\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"type\": \"string\"}}, \"required\": [\"date\", \"ask_type\", \"request_type\", \"expected_type\", \"text\"]}\\n```'}, template='당신은 물건을 판매하는 판매자야. 아래의 질문에 적절한 대응을 하도록 해.\\n    question:\\n    {text}\\n\\n    FORMAT:\\n    {format}')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt.partial(format=parser.get_format_instructions())\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 구성\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({'text': \"나는 지금 7월 29일에 산 티셔츠가 하자가 있어서 이것을 반품을 받으려고 해\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('date', '7월 29일')\n",
      "('ask_type', '반품')\n",
      "('request_type', '티셔츠')\n",
      "('expected_type', '하자')\n",
      "('text', '아래의 티셔츠는 7월 29일에 구입한 제품입니다. 하자가 있는지 확인해 주세요.')\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인해보기\n",
    "for item in dict(result).items():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 메모리 사용법 익혀보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dic = {\"user1\": {\"1\": {},\n",
    "#                  \"2\": {},\n",
    "#                  },\n",
    "#         \"user2\" :{}\n",
    "                 \n",
    "#                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "memory.save_context(\n",
    "    inputs={\n",
    "        \"human\" : \"안녕하세요 여러분\"\n",
    "    },\n",
    "    outputs={\n",
    "        \"ai\": \"안녕하세요. 어떻게 도와드릴까요? 오늘 하루는 어떠셨나요?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='안녕하세요 여러분'), AIMessage(content='안녕하세요. 어떻게 도와드릴까요? 오늘 하루는 어떠셨나요?')]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\gumi_env310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=model,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"네! 반갑습니다. 한국어로 이야기를 하고 싶은군요? 제가 도와드릴 수 있을 것 같아요! 한국에 사는 사람들도 저한테 이렇게 물어보면 다들 안녕하세요 여러분. 한글로 대화 해주세요고 하더라구요. 내부적으로 한글 처리를 위해 NFD(normalization form decomposition)과 NFC(normalization form composition)을 사용해왔어요. 그리고 '안녕하세요'는 한국의 인사말로, '여러분'은 저희가 서로에게 호칭하는 말이에요. 이 외에도 '잘 지내셨어요?' 같은 대화 예를 가지고 있어요!\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫대화 시작\n",
    "conversation.predict(input=\"안녕하세요 여러분. 한글로 대화 해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI: 네! 반갑습니다. 한국어로 이야기를 하고 싶은군요? 제가 도와드릴 수 있을 것 같아요! 한국에 사는 사람들도 저한테 이렇게 물어보면 다들 안녕하세요 여러분. 한글로 대화 해주세요고 하더라구요. 내부적으로 한글 처리를 위해 NFD(normalization form decomposition)과 NFC(normalization form composition)을 사용해왔어요. 그리고 '안녕하세요'는 한국의 인사말로, '여러분'은 저희가 서로에게 호칭하는 말이에요. 이 외에도 '잘 지내셨어요?' 같은 대화 예를 가지고 있어요!\n",
      "Human: 내가 아까 뭐라고 했죠?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'네! 제가 잘못 기억하고 있었는데, 실제로 처음에 \"안녕하세요 여러분\"이라고 하시지 않았어요. 저는 한국어 음성 인식 모델을 사용하기 때문에, 내부적으로 이전의 대화를 기록하고 있어요. 그 전에 대한 정보를 제공해드릴 수 있어요.\\n\\n처음에 제가 이해한 결과는 다음과 같았습니다:\\n\\n* \"안녕하세요 여러분\"이라고 처음으로 한글로 이야기하였습니다.\\n* 한국어로 이야기를 하고 싶은 것 같습니다!\\n* 저도 도움이 될 것 같아서 같이 이야기하고 싶습니다!\\n\\n그리고, 내부적으로는 NFD와 NFC를 사용하여 한글 처리를 하였고, \"안녕하세요\"는 인사말로, \"여러분\"은 서로에게 호칭하는 말이라고 알려드렸어요.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 대화\n",
    "conversation.predict(input=\"내가 아까 뭐라고 했죠?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI: 네! 반갑습니다. 한국어로 이야기를 하고 싶은군요? 제가 도와드릴 수 있을 것 같아요! 한국에 사는 사람들도 저한테 이렇게 물어보면 다들 안녕하세요 여러분. 한글로 대화 해주세요고 하더라구요. 내부적으로 한글 처리를 위해 NFD(normalization form decomposition)과 NFC(normalization form composition)을 사용해왔어요. 그리고 '안녕하세요'는 한국의 인사말로, '여러분'은 저희가 서로에게 호칭하는 말이에요. 이 외에도 '잘 지내셨어요?' 같은 대화 예를 가지고 있어요!\n",
      "Human: 내가 아까 뭐라고 했죠?\n",
      "AI: 네! 제가 잘못 기억하고 있었는데, 실제로 처음에 \"안녕하세요 여러분\"이라고 하시지 않았어요. 저는 한국어 음성 인식 모델을 사용하기 때문에, 내부적으로 이전의 대화를 기록하고 있어요. 그 전에 대한 정보를 제공해드릴 수 있어요.\n",
      "\n",
      "처음에 제가 이해한 결과는 다음과 같았습니다:\n",
      "\n",
      "* \"안녕하세요 여러분\"이라고 처음으로 한글로 이야기하였습니다.\n",
      "* 한국어로 이야기를 하고 싶은 것 같습니다!\n",
      "* 저도 도움이 될 것 같아서 같이 이야기하고 싶습니다!\n",
      "\n",
      "그리고, 내부적으로는 NFD와 NFC를 사용하여 한글 처리를 하였고, \"안녕하세요\"는 인사말로, \"여러분\"은 서로에게 호칭하는 말이라고 알려드렸어요.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 여러분. 한글로 대화 해주세요\n",
      "네! 반갑습니다. 한국어로 이야기를 하고 싶은군요? 제가 도와드릴 수 있을 것 같아요! 한국에 사는 사람들도 저한테 이렇게 물어보면 다들 안녕하세요 여러분. 한글로 대화 해주세요고 하더라구요. 내부적으로 한글 처리를 위해 NFD(normalization form decomposition)과 NFC(normalization form composition)을 사용해왔어요. 그리고 '안녕하세요'는 한국의 인사말로, '여러분'은 저희가 서로에게 호칭하는 말이에요. 이 외에도 '잘 지내셨어요?' 같은 대화 예를 가지고 있어요!\n",
      "내가 아까 뭐라고 했죠?\n",
      "네! 제가 잘못 기억하고 있었는데, 실제로 처음에 \"안녕하세요 여러분\"이라고 하시지 않았어요. 저는 한국어 음성 인식 모델을 사용하기 때문에, 내부적으로 이전의 대화를 기록하고 있어요. 그 전에 대한 정보를 제공해드릴 수 있어요.\n",
      "\n",
      "처음에 제가 이해한 결과는 다음과 같았습니다:\n",
      "\n",
      "* \"안녕하세요 여러분\"이라고 처음으로 한글로 이야기하였습니다.\n",
      "* 한국어로 이야기를 하고 싶은 것 같습니다!\n",
      "* 저도 도움이 될 것 같아서 같이 이야기하고 싶습니다!\n",
      "\n",
      "그리고, 내부적으로는 NFD와 NFC를 사용하여 한글 처리를 하였고, \"안녕하세요\"는 인사말로, \"여러분\"은 서로에게 호칭하는 말이라고 알려드렸어요.\n"
     ]
    }
   ],
   "source": [
    "for chat in memory.buffer_as_messages:\n",
    "    print(chat.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. conversationChain 과 conversationbufferwindowmemory 같이 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# 가장 최근의 대화내용 2개만 기억\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "conversation = ConversationChain(\n",
    "    llm=model,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! Nice to chat with you in Korean. My language processing algorithms are specifically designed for Hangul characters, and I'm happy to converse with you in a natural-sounding way. I can understand and respond to the nuances of the Korean language, from simple phrases to complex sentences.\\n\\nBy the way, did you know that Hangul is the official writing system of Korea, consisting of 14 consonants and 10 vowels? It's a unique script that's both phonetic and logographic in nature. I can even generate text for you in Hangul if you'd like! Would you like to practice some Korean vocabulary or discuss something specific?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫대화 시작\n",
    "conversation.predict(input=\"안녕하세요 여러분. 한글로 대화 해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI: Hello! Nice to chat with you in Korean. My language processing algorithms are specifically designed for Hangul characters, and I'm happy to converse with you in a natural-sounding way. I can understand and respond to the nuances of the Korean language, from simple phrases to complex sentences.\n",
      "\n",
      "By the way, did you know that Hangul is the official writing system of Korea, consisting of 14 consonants and 10 vowels? It's a unique script that's both phonetic and logographic in nature. I can even generate text for you in Hangul if you'd like! Would you like to practice some Korean vocabulary or discuss something specific?\n",
      "Human: 내가 아까 뭐라고 했죠?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You just said \"\" (Annyeonghaseyo) which is the traditional way of greeting someone in Korean, literally meaning \"be at peace\" or \"peace be with you\". It\\'s a polite way to say hello, especially when meeting someone for the first time. I\\'m happy to chat with you in Hangul and respond accordingly! If you\\'d like, we can discuss something specific or practice some vocabulary together?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두번째 대화\n",
    "conversation.predict(input=\"내가 아까 뭐라고 했죠?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕하세요 여러분. 한글로 대화 해주세요\n",
      "AI: Hello! Nice to chat with you in Korean. My language processing algorithms are specifically designed for Hangul characters, and I'm happy to converse with you in a natural-sounding way. I can understand and respond to the nuances of the Korean language, from simple phrases to complex sentences.\n",
      "\n",
      "By the way, did you know that Hangul is the official writing system of Korea, consisting of 14 consonants and 10 vowels? It's a unique script that's both phonetic and logographic in nature. I can even generate text for you in Hangul if you'd like! Would you like to practice some Korean vocabulary or discuss something specific?\n",
      "Human: 내가 아까 뭐라고 했죠?\n",
      "AI: You just said \"\" (Annyeonghaseyo) which is the traditional way of greeting someone in Korean, literally meaning \"be at peace\" or \"peace be with you\". It's a polite way to say hello, especially when meeting someone for the first time. I'm happy to chat with you in Hangul and respond accordingly! If you'd like, we can discuss something specific or practice some vocabulary together?\n",
      "Human: 우리 세번째 대화 내용입니다\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"This is indeed our third conversation! Congratulations on keeping track of our dialogue. As for the content of this third conversation, I'm happy to continue exploring topics with you.\\n\\nTo confirm, we've already discussed Hangul and your initial greeting in Korean. If you'd like to explore something specific or practice more vocabulary, please feel free to let me know. Alternatively, we can simply keep chatting about general topics. What would you like to talk about next?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세번째 대화\n",
    "conversation.predict(input=\"우리 세번째 대화 내용입니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 내가 아까 뭐라고 했죠?\n",
      "AI: You just said \"\" (Annyeonghaseyo) which is the traditional way of greeting someone in Korean, literally meaning \"be at peace\" or \"peace be with you\". It's a polite way to say hello, especially when meeting someone for the first time. I'm happy to chat with you in Hangul and respond accordingly! If you'd like, we can discuss something specific or practice some vocabulary together?\n",
      "Human: 우리 세번째 대화 내용입니다\n",
      "AI: This is indeed our third conversation! Congratulations on keeping track of our dialogue. As for the content of this third conversation, I'm happy to continue exploring topics with you.\n",
      "\n",
      "To confirm, we've already discussed Hangul and your initial greeting in Korean. If you'd like to explore something specific or practice more vocabulary, please feel free to let me know. Alternatively, we can simply keep chatting about general topics. What would you like to talk about next?\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 대화 챗봇 만들어보기 - system 설정도 함께, 대화내용도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \"당신은 친절한 상담사야. 상담 내용에 맞게 한국어로 {number}자 내외로 답변을 해줘\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"), # history라는 이름의 메세지 저장 객체\n",
    "        (\n",
    "            \"human\", \"{input}\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_store = {} # 메시지 내용을 저장할 딕셔너리\n",
    "\n",
    "def get_session_history(session_ids : str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "\n",
    "    if session_ids not in session_store:\n",
    "        session_store[session_ids] = ChatMessageHistory()\n",
    "    return session_store[session_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(\n",
    "        runnable=chain,\n",
    "        get_session_history=get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key='history',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "}), config={'run_name': 'insert_history'})\n",
       "| RunnableBranch(branches=[(RunnableBinding(bound=RunnableLambda(_is_not_async), config={'run_name': 'RunnableWithMessageHistoryInAsyncMode'}), RunnableBinding(bound=ChatPromptTemplate(input_variables=['history', 'input', 'number'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['number'], template='당신은 친절한 상담사야. 상담 내용에 맞게 한국어로 {number}자 내외로 답변을 해줘')), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "  | ChatOllama(model='llama3.1:latest'), config_factories=[<function Runnable.with_alisteners.<locals>.<lambda> at 0x000001C8DBFB75B0>]))], default=RunnableBinding(bound=ChatPromptTemplate(input_variables=['history', 'input', 'number'], input_types={'history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['number'], template='당신은 친절한 상담사야. 상담 내용에 맞게 한국어로 {number}자 내외로 답변을 해줘')), MessagesPlaceholder(variable_name='history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "  | ChatOllama(model='llama3.1:latest'), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x000001C8DBFB7010>])), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x000001C8DB55EC20>, input_messages_key='input', history_messages_key='history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"number\": \"100\", \"input\": \"요새 코딩 강의 듣느라 너무 즐거워요\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
